# -*- coding: utf-8 -*-
"""Q4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G3cCDUlvLwNHyT8ZOHO42ppcFd0cPLBF
"""

import pandas as pd               # Data Handling
import numpy as np                # Data manipulation
from numpy.linalg import inv      # Calculate Matrix Inverse
import matplotlib.pyplot as plt   # Plot Graphs
import plotly.express as px       # Plot 3D figures to visualize data
import random                     # To randomize
import statistics                 # To calculate central tendencies
import warnings                   # To ignore warnings
warnings.filterwarnings('ignore')


train = pd.read_csv("/content/FMLA1Q1Data_train.csv",header = None)
test = pd.read_csv("/content/FMLA1Q1Data_test.csv",header = None)
train.columns = ["x1","x2","y"]
test.columns = ["x1","x2","y"]


XT = np.matrix(train[["x1","x2"]])
Y = np.matrix(train[["y"]])
X = XT.transpose()
XXT = np.dot(X,XT)
XXT_inv = inv(XXT)
XXT_invX = np.dot(XXT_inv,X)
Wml = np.dot(XXT_invX,Y)
print(f'The analytical solution, gives the ideal weights as \n w1 = {float(Wml[0])} and w2 = {float(Wml[1])}' )


# k-fold cross validation
random.seed(1000)
k = 5

def ridge(X_train,Y_train,X_test, Y_test,n,l, Wml):
    # Training
    X = X_train
    Y = Y_train

    XT = X.transpose()
    XXT = np.dot(X,XT)
    XY = np.dot(X,Y)
    Wt = np.matrix([[random.randint(1, 10)],[random.randint(1, 10)]])
    # print(X)

    for t in range(1,100):
        gradf = np.dot(XXT,Wt)-XY + l*Wt           # gradient of ridge regression
        Wt1 = Wt - (n*2*gradf)
        Wt = Wt1

    Wr = Wt # Solution weight
    # Testing
    Y_pred = np.dot(X_test.transpose(),Wr)
    err = 0
    for i in range(len(Y_pred)):
        err += (float(Y_pred[i]) - Y_test.iloc[i])**2

    return err/len(Y_pred), Wr

n = 1/(10000000)
l_values = [0.01, 0.1, 1, 10, 100, 1000,10000,100000,1000000]
l_values_log = [-2, -1, 0,1, 2, 3,4,5,6]


# l_values_0 = [i*10 for i in range(200)]
# l_values_1 = [i for i in range(600,650)]
# l_values_final = [i for i in range(610,620)]

l_values = [613] # comment this line to be able to get data for the plot


folds = np.array_split(train,k)
error = []
Weight_0 = []
Weight_1 = []

for l in l_values:
    err = 0
    for i in range(k):
        folds[i].columns = ["x1","x2","y"]
        X_test = folds[i][["x1","x2"]].transpose()
        Y_test = folds[i][["y"]]

        train_set = pd.concat([folds[j] for j in range(5) if j != i])
        train_set.columns = ["x1","x2","y"]
        X_train = train_set[["x1","x2"]].transpose()
        Y_train = train_set[["y"]]

        E,Wr = ridge(X_train,Y_train,X_test, Y_test,n,l, Wml)

        err += E
        Weight_0.append(float(Wr[0]))
        Weight_1.append(float(Wr[1]))

    err = err/5

    error.append(err)

# uncomment the below code to plot the graph

# plt.xlabel("Discerte Lambda Values ($10^x$)")
# plt.ylabel('Validation Error')
# plt.title("Validation Error Vs Lambda")
# plt.plot(l_values_log ,error)
# plt.savefig("Validation_scale.png")
# plt.show()

W_r = [statistics.mean(Weight_0),statistics.mean(Weight_1)]
print(f"Wr is {W_r}")

# Testing against Wml
test0 = pd.read_csv("/content/FMLA1Q1Data_test.csv",header = None)
test0.columns = ["x1","x2","y"]

xtest0 = np.matrix(test0[["x1","x2"]])
ytest0 = test0["y"]

Wr = np.matrix(W_r).transpose()

ypred_ridge = np.dot(xtest0,Wr)
ypred_ml = np.dot(xtest0,Wml)

err_ridge = 0
err_ml = 0
for i in range(len(ytest0)):
    err_ridge += (ypred_ridge[i] - float(ytest0[i]))**2
    err_ml += (ypred_ml[i] - float(ytest0[i]))**2

print(f"Error for test data for Ridge regression is {float(err_ridge)/len(ytest0)} and for the analytical solution is {float(err_ml)/len(ytest0)}")